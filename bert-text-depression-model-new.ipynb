{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9150656,"sourceType":"datasetVersion","datasetId":5527467},{"sourceId":9150822,"sourceType":"datasetVersion","datasetId":5527600},{"sourceId":9183749,"sourceType":"datasetVersion","datasetId":5551072},{"sourceId":9183832,"sourceType":"datasetVersion","datasetId":5551138}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import libraries\nimport os\nimport tensorflow as tf\nimport keras\nimport pandas as pd\nimport numpy as np\nimport collections\nimport gc\nfrom sklearn.model_selection import KFold\nfrom transformers import BertTokenizer,TFBertModel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-24T00:55:53.644917Z","iopub.execute_input":"2024-09-24T00:55:53.645140Z","iopub.status.idle":"2024-09-24T00:56:32.480272Z","shell.execute_reply.started":"2024-09-24T00:55:53.645112Z","shell.execute_reply":"2024-09-24T00:56:32.479458Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1727139360.354901      30 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0924 00:56:00.362941255      30 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0924 00:56:00.362958023      30 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0924 00:56:00.362961282      30 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0924 00:56:00.362963644      30 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0924 00:56:00.362966221      30 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0924 00:56:00.362968531      30 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0924 00:56:00.362970799      30 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0924 00:56:00.362973014      30 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0924 00:56:00.362975204      30 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0924 00:56:00.362977353      30 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0924 00:56:00.362979548      30 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0924 00:56:00.362981756      30 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0924 00:56:00.362983941      30 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0924 00:56:00.362986131      30 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0924 00:56:00.362988306      30 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0924 00:56:00.362990478      30 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0924 00:56:00.362992803      30 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0924 00:56:00.362995053      30 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0924 00:56:00.362997278      30 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0924 00:56:00.362999510      30 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0924 00:56:00.363001728      30 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0924 00:56:00.363003938      30 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0924 00:56:00.363006209      30 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0924 00:56:00.363008435      30 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0924 00:56:00.363010583      30 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0924 00:56:00.363012730      30 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0924 00:56:00.363014968      30 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0924 00:56:00.363017181      30 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0924 00:56:00.363019513      30 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0924 00:56:00.363022619      30 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0924 00:56:00.363025046      30 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0924 00:56:00.363027342      30 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0924 00:56:00.363029708      30 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0924 00:56:00.363031921      30 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0924 00:56:00.363034159      30 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0924 00:56:00.363036350      30 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0924 00:56:00.363038489      30 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0924 00:56:00.363040661      30 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0924 00:56:00.363042921      30 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0924 00:56:00.363045126      30 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0924 00:56:00.363047306      30 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0924 00:56:00.363049440      30 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0924 00:56:00.363051646      30 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0924 00:56:00.363053889      30 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0924 00:56:00.363056139      30 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0924 00:56:00.363220108      30 ev_epoll1_linux.cc:123]               grpc epoll fd: 58\nD0924 00:56:00.363230883      30 ev_posix.cc:113]                      Using polling engine: epoll1\nD0924 00:56:00.373539375      30 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0924 00:56:00.373549915      30 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0924 00:56:00.373558164      30 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0924 00:56:00.373561207      30 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0924 00:56:00.373564107      30 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0924 00:56:00.373566802      30 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0924 00:56:00.373590522      30 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0924 00:56:00.373604574      30 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0924 00:56:00.373619938      30 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0924 00:56:00.373639598      30 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0924 00:56:00.373652086      30 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0924 00:56:00.373655160      30 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0924 00:56:00.373658823      30 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0924 00:56:00.373664635      30 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0924 00:56:00.373667598      30 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0924 00:56:00.373670610      30 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0924 00:56:00.373697959      30 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0924 00:56:00.375774143      30 ev_epoll1_linux.cc:359]               grpc epoll fd: 60\nI0924 00:56:00.376889464      30 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0924 00:56:00.380466815     123 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0924 00:56:00.380524301     123 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0924 00:56:00.386491605      30 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-09-24T00:56:00.386476598+00:00\", grpc_status:2}\n/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"# configure notebook to run on tpu\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:32.481361Z","iopub.execute_input":"2024-09-24T00:56:32.481923Z","iopub.status.idle":"2024-09-24T00:56:40.998400Z","shell.execute_reply.started":"2024-09-24T00:56:32.481889Z","shell.execute_reply":"2024-09-24T00:56:40.997566Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727139396.709117      30 service.cc:145] XLA service 0x5d2cd8446360 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1727139396.709163      30 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1727139396.709167      30 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1727139396.709170      30 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1727139396.709173      30 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1727139396.709176      30 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1727139396.709178      30 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1727139396.709181      30 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1727139396.709184      30 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# load files function\ntext_files={}\n\ndef load_files(directory, text_files):\n    for filename in os.listdir(directory):\n        with open(directory+'/'+filename, encoding=\"utf8\") as file:\n            lines=''\n            for line in file:\n                line=line.replace(\"\\n\", \"\")\n                lines+=line\n            text_files[filename]=lines","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:40.999316Z","iopub.execute_input":"2024-09-24T00:56:40.999562Z","iopub.status.idle":"2024-09-24T00:56:41.004147Z","shell.execute_reply.started":"2024-09-24T00:56:40.999537Z","shell.execute_reply":"2024-09-24T00:56:41.003434Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# load the files, sort the files, and append files in a list\nload_files('/kaggle/input/patient-text-files-zipped/patient_txt_files', text_files)\ntext_files = collections.OrderedDict(sorted(text_files.items()))\nX=[]\nfor key in text_files:\n    X.append(text_files[key])\nX=np.array(X)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:41.005943Z","iopub.execute_input":"2024-09-24T00:56:41.006346Z","iopub.status.idle":"2024-09-24T00:56:41.379960Z","shell.execute_reply.started":"2024-09-24T00:56:41.006320Z","shell.execute_reply":"2024-09-24T00:56:41.379150Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# load and sort the labels\ny=pd.read_csv('/kaggle/input/patient-labels/Train.csv')\ny.sort_values(y.columns[0], axis=0, inplace=True)\ny=y['Label']\ny.loc[y > 0] = 1\ny=np.asarray(y).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:41.380849Z","iopub.execute_input":"2024-09-24T00:56:41.381088Z","iopub.status.idle":"2024-09-24T00:56:41.397522Z","shell.execute_reply.started":"2024-09-24T00:56:41.381064Z","shell.execute_reply":"2024-09-24T00:56:41.396746Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# configure kfold split\nkfold = KFold(n_splits=5, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:41.398461Z","iopub.execute_input":"2024-09-24T00:56:41.398724Z","iopub.status.idle":"2024-09-24T00:56:41.401966Z","shell.execute_reply.started":"2024-09-24T00:56:41.398699Z","shell.execute_reply":"2024-09-24T00:56:41.401209Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# define function to create, train, and evaluate model\ndef create_run_model(X_train, X_cv, y_train, y_cv, fold_loss, fold_accuracy, fold_precision, fold_recall, predict):\n    \n    # load the tokenizer and pretrained model\n    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n    bert_model = TFBertModel.from_pretrained('bert-base-chinese')\n    \n    # encodes the text with tokens\n    def encode_texts(texts, tokenizer, max_length=512):\n\n        encoding = tokenizer.batch_encode_plus(texts, add_special_tokens=True,max_length=max_length,padding='max_length',truncation=True,return_tensors='tf')\n\n        return encoding['input_ids'], encoding['attention_mask']\n\n    # define the early stop callback function to monitor validation loss\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n    # define the neural network layers\n    input_ids_layer = tf.keras.layers.Input(shape=(512,), dtype=tf.int32, name='input_ids')\n    attention_mask_layer = tf.keras.layers.Input(shape=(512,), dtype=tf.int32, name='attention_mask')\n    bert_output = bert_model(input_ids_layer, attention_mask=attention_mask_layer)\n    dropout = tf.keras.layers.Dropout(0.12, name='dropout')(bert_output.pooler_output)\n    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(dropout)\n\n    # define the model\n    model = tf.keras.Model(inputs=[input_ids_layer, attention_mask_layer], outputs=[output])\n\n    # compile the model\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')])\n\n    # tokenize the data \n    input_ids, attention_masks=encode_texts(X_train, tokenizer)\n    input_ids_cv, attention_mask_cv = encode_texts(X_cv, tokenizer)\n\n    # train the model\n    history = model.fit([input_ids, attention_masks], y_train, epochs=30, callbacks=[early_stop], validation_data=([input_ids_cv, attention_mask_cv], y_cv))\n\n    # evaluate the model\n    evaluation = model.evaluate([input_ids_cv, attention_mask_cv], y_cv)\n    \n    print()\n    print(f\"Evaluation Results: Validation Loss - {evaluation[0]}, Validation Accuracy - {evaluation[1]}, Validation Precision - {evaluation[2]}, Validation Recall - {evaluation[3]}\")\n    print()\n    \n    if predict==1:\n        return 0\n    \n    # append evaluation metrics in lists\n    else:\n        fold_loss.append(evaluation[0])\n        fold_accuracy.append(evaluation[1])\n        fold_precision.append(evaluation[2])\n        fold_recall.append(evaluation[3])\n\n        # delete the model after training and evaluating to reset weights\n        del model\n        keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:41.403177Z","iopub.execute_input":"2024-09-24T00:56:41.403489Z","iopub.status.idle":"2024-09-24T00:56:41.416317Z","shell.execute_reply.started":"2024-09-24T00:56:41.403458Z","shell.execute_reply":"2024-09-24T00:56:41.415657Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# initialize kfold metrics\nfold = 1\n\nfold_loss=[]\nfold_accuracy=[]\nfold_precision=[]\nfold_recall=[]","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:41.417127Z","iopub.execute_input":"2024-09-24T00:56:41.417350Z","iopub.status.idle":"2024-09-24T00:56:41.432461Z","shell.execute_reply.started":"2024-09-24T00:56:41.417329Z","shell.execute_reply":"2024-09-24T00:56:41.431761Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# run kfold cross-validation on the training data only\nwith tpu_strategy.scope():\n\n    for train, cv in kfold.split(X, y):\n\n        X_train = X[train]\n        X_cv = X[cv]\n        y_train = y[train]\n        y_cv = y[cv]\n\n        print(\"Fold number:\", fold)\n\n        create_run_model(X_train, X_cv, y_train, y_cv, fold_loss, fold_accuracy, fold_precision, fold_recall, 0)\n\n        fold+=1","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:56:41.433267Z","iopub.execute_input":"2024-09-24T00:56:41.433531Z","iopub.status.idle":"2024-09-24T02:57:14.930705Z","shell.execute_reply.started":"2024-09-24T00:56:41.433505Z","shell.execute_reply":"2024-09-24T02:57:14.929164Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Fold number: 1\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727139404.976191      30 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2024-09-24 00:58:10.405312: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\nI0000 00:00:1727139493.119827     849 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(d7d064156a71371a:0:0), session_name()\nI0000 00:00:1727139527.456019     849 tpu_compile_op_common.cc:245] Compilation of d7d064156a71371a:0:0 with session name  took 34.336146489s and succeeded\nI0000 00:00:1727139527.546673     849 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(d7d064156a71371a:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_5049897138427391008\", property.function_library_fingerprint = 15840757827652016438, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"4,512,;4,512,;4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727139527.546748     849 tpu_compilation_cache_interface.cc:541] After adding entry for key d7d064156a71371a:0:0 with session_name  cache is 1 entries (225267582 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"2/3 [===================>..........] - ETA: 0s - loss: 0.8303 - accuracy: 0.5469 - precision: 0.6667 - recall: 0.2424          ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727139527.930830     829 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(7b63916b33e8371b:0:0), session_name()\nI0000 00:00:1727139558.535691     829 tpu_compile_op_common.cc:245] Compilation of 7b63916b33e8371b:0:0 with session name  took 30.604820068s and succeeded\nI0000 00:00:1727139558.617538     829 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(7b63916b33e8371b:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_5049897138427391008\", property.function_library_fingerprint = 15840757827652016438, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"2,512,;2,512,;2,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727139558.617599     829 tpu_compilation_cache_interface.cc:541] After adding entry for key 7b63916b33e8371b:0:0 with session_name  cache is 2 entries (425987689 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"3/3 [==============================] - ETA: 0s - loss: 0.7988 - accuracy: 0.5775 - precision: 0.7368 - recall: 0.3590","output_type":"stream"},{"name":"stderr","text":"2024-09-24 00:59:29.204287: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\nI0000 00:00:1727139569.903833     798 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(5b9afb5a1847bfc3:0:0), session_name()\nI0000 00:00:1727139574.019770     798 tpu_compile_op_common.cc:245] Compilation of 5b9afb5a1847bfc3:0:0 with session name  took 4.115882123s and succeeded\nI0000 00:00:1727139574.044529     798 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(5b9afb5a1847bfc3:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_11809109812596905441\", property.function_library_fingerprint = 3711174026116660539, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"3,512,;3,512,;3,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727139574.044572     798 tpu_compilation_cache_interface.cc:541] After adding entry for key 5b9afb5a1847bfc3:0:0 with session_name  cache is 3 entries (479819916 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"3/3 [==============================] - 144s 24s/step - loss: 0.7988 - accuracy: 0.5775 - precision: 0.7368 - recall: 0.3590 - val_loss: 0.6096 - val_accuracy: 0.6111 - val_precision: 0.5625 - val_recall: 1.0000\nEpoch 2/30\n3/3 [==============================] - 1s 645ms/step - loss: 0.5997 - accuracy: 0.6901 - precision: 0.6441 - recall: 0.9744 - val_loss: 0.6049 - val_accuracy: 0.6111 - val_precision: 0.5625 - val_recall: 1.0000\nEpoch 3/30\n3/3 [==============================] - 1s 651ms/step - loss: 0.5303 - accuracy: 0.7183 - precision: 0.6727 - recall: 0.9487 - val_loss: 0.4918 - val_accuracy: 0.9444 - val_precision: 0.9000 - val_recall: 1.0000\nEpoch 4/30\n3/3 [==============================] - 1s 600ms/step - loss: 0.5351 - accuracy: 0.7606 - precision: 0.7895 - recall: 0.7692 - val_loss: 0.4263 - val_accuracy: 0.8333 - val_precision: 0.8750 - val_recall: 0.7778\nEpoch 5/30\n3/3 [==============================] - 1s 684ms/step - loss: 0.4575 - accuracy: 0.8028 - precision: 0.8571 - recall: 0.7692 - val_loss: 0.3542 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 6/30\n3/3 [==============================] - 1s 432ms/step - loss: 0.4094 - accuracy: 0.8310 - precision: 0.8000 - recall: 0.9231 - val_loss: 0.3701 - val_accuracy: 0.7778 - val_precision: 0.6923 - val_recall: 1.0000\nEpoch 7/30\n3/3 [==============================] - 1s 631ms/step - loss: 0.4135 - accuracy: 0.8028 - precision: 0.7551 - recall: 0.9487 - val_loss: 0.3283 - val_accuracy: 0.8889 - val_precision: 0.8182 - val_recall: 1.0000\nEpoch 8/30\n3/3 [==============================] - 1s 635ms/step - loss: 0.3329 - accuracy: 0.8592 - precision: 0.8222 - recall: 0.9487 - val_loss: 0.2822 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 9/30\n3/3 [==============================] - 1s 420ms/step - loss: 0.2646 - accuracy: 0.9577 - precision: 0.9500 - recall: 0.9744 - val_loss: 0.2944 - val_accuracy: 0.8333 - val_precision: 0.8750 - val_recall: 0.7778\nEpoch 10/30\n3/3 [==============================] - 1s 648ms/step - loss: 0.2632 - accuracy: 0.9437 - precision: 1.0000 - recall: 0.8974 - val_loss: 0.2560 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 11/30\n3/3 [==============================] - 1s 430ms/step - loss: 0.2303 - accuracy: 0.9014 - precision: 0.8810 - recall: 0.9487 - val_loss: 0.2641 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 12/30\n3/3 [==============================] - 1s 664ms/step - loss: 0.2344 - accuracy: 0.9155 - precision: 0.8837 - recall: 0.9744 - val_loss: 0.2440 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 13/30\n3/3 [==============================] - 1s 637ms/step - loss: 0.1420 - accuracy: 0.9577 - precision: 0.9737 - recall: 0.9487 - val_loss: 0.2306 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 14/30\n3/3 [==============================] - 1s 640ms/step - loss: 0.1501 - accuracy: 0.9718 - precision: 1.0000 - recall: 0.9487 - val_loss: 0.2197 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 15/30\n3/3 [==============================] - 1s 430ms/step - loss: 0.1456 - accuracy: 0.9577 - precision: 0.9737 - recall: 0.9487 - val_loss: 0.2247 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 16/30\n3/3 [==============================] - 1s 431ms/step - loss: 0.0854 - accuracy: 0.9718 - precision: 0.9744 - recall: 0.9744 - val_loss: 0.2642 - val_accuracy: 0.9444 - val_precision: 0.9000 - val_recall: 1.0000\nEpoch 17/30\n3/3 [==============================] - 1s 420ms/step - loss: 0.0990 - accuracy: 0.9859 - precision: 1.0000 - recall: 0.9744 - val_loss: 0.2782 - val_accuracy: 0.9444 - val_precision: 0.9000 - val_recall: 1.0000\nEpoch 18/30\n3/3 [==============================] - 1s 411ms/step - loss: 0.0830 - accuracy: 0.9859 - precision: 1.0000 - recall: 0.9744 - val_loss: 0.2646 - val_accuracy: 0.9444 - val_precision: 0.9000 - val_recall: 1.0000\nEpoch 19/30\n3/3 [==============================] - 1s 419ms/step - loss: 0.0647 - accuracy: 0.9859 - precision: 1.0000 - recall: 0.9744 - val_loss: 0.2463 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 20/30\n3/3 [==============================] - 1s 432ms/step - loss: 0.0544 - accuracy: 0.9859 - precision: 1.0000 - recall: 0.9744 - val_loss: 0.2398 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 21/30\n3/3 [==============================] - 1s 428ms/step - loss: 0.0379 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 22/30\n3/3 [==============================] - 1s 437ms/step - loss: 0.0394 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 23/30\n3/3 [==============================] - 1s 412ms/step - loss: 0.0323 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\nEpoch 24/30\n3/3 [==============================] - 1s 414ms/step - loss: 0.0233 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n1/1 [==============================] - 1s 616ms/step - loss: 0.2197 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889\n\nEvaluation Results: Validation Loss - 0.21972471475601196, Validation Accuracy - 0.8888888955116272, Validation Precision - 0.8888888955116272, Validation Recall - 0.8888888955116272\n\nFold number: 2\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n3/3 [==============================] - 121s 24s/step - loss: 0.6618 - accuracy: 0.6197 - precision: 0.6216 - recall: 0.6389 - val_loss: 0.3308 - val_accuracy: 0.8889 - val_precision: 0.8571 - val_recall: 1.0000\nEpoch 2/30\n3/3 [==============================] - 66s 19s/step - loss: 0.4263 - accuracy: 0.8451 - precision: 0.8205 - recall: 0.8889 - val_loss: 0.4632 - val_accuracy: 0.7778 - val_precision: 1.0000 - val_recall: 0.6667\nEpoch 3/30\n3/3 [==============================] - 66s 19s/step - loss: 0.4869 - accuracy: 0.7606 - precision: 0.8800 - recall: 0.6111 - val_loss: 0.2390 - val_accuracy: 0.9444 - val_precision: 0.9231 - val_recall: 1.0000\nEpoch 4/30\n3/3 [==============================] - 67s 20s/step - loss: 0.3323 - accuracy: 0.8873 - precision: 0.8684 - recall: 0.9167 - val_loss: 0.2722 - val_accuracy: 0.8889 - val_precision: 0.8571 - val_recall: 1.0000\nEpoch 5/30\n3/3 [==============================] - 66s 20s/step - loss: 0.4263 - accuracy: 0.8169 - precision: 0.7447 - recall: 0.9722 - val_loss: 0.2004 - val_accuracy: 0.9444 - val_precision: 0.9231 - val_recall: 1.0000\nEpoch 6/30\n3/3 [==============================] - 66s 20s/step - loss: 0.2799 - accuracy: 0.9014 - precision: 0.8718 - recall: 0.9444 - val_loss: 0.1737 - val_accuracy: 0.9444 - val_precision: 1.0000 - val_recall: 0.9167\nEpoch 7/30\n3/3 [==============================] - 66s 19s/step - loss: 0.2731 - accuracy: 0.8873 - precision: 0.9118 - recall: 0.8611 - val_loss: 0.2746 - val_accuracy: 0.8889 - val_precision: 1.0000 - val_recall: 0.8333\nEpoch 8/30\n3/3 [==============================] - 66s 19s/step - loss: 0.2291 - accuracy: 0.9296 - precision: 0.9429 - recall: 0.9167 - val_loss: 0.1615 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 9/30\n3/3 [==============================] - 67s 20s/step - loss: 0.1698 - accuracy: 0.9155 - precision: 0.9167 - recall: 0.9167 - val_loss: 0.1336 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 10/30\n3/3 [==============================] - 65s 19s/step - loss: 0.1344 - accuracy: 0.9718 - precision: 0.9722 - recall: 0.9722 - val_loss: 0.1170 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 11/30\n3/3 [==============================] - 65s 19s/step - loss: 0.1351 - accuracy: 0.9577 - precision: 0.9459 - recall: 0.9722 - val_loss: 0.1211 - val_accuracy: 0.9444 - val_precision: 1.0000 - val_recall: 0.9167\nEpoch 12/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0977 - accuracy: 0.9859 - precision: 0.9730 - recall: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9444 - val_precision: 1.0000 - val_recall: 0.9167\nEpoch 13/30\n3/3 [==============================] - 66s 19s/step - loss: 0.1051 - accuracy: 0.9859 - precision: 1.0000 - recall: 0.9722 - val_loss: 0.1986 - val_accuracy: 0.9444 - val_precision: 1.0000 - val_recall: 0.9167\nEpoch 14/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0627 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0813 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 15/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0684 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9444 - val_precision: 0.9231 - val_recall: 1.0000\nEpoch 16/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0963 - accuracy: 0.9718 - precision: 0.9474 - recall: 1.0000 - val_loss: 0.0696 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 17/30\n3/3 [==============================] - 67s 20s/step - loss: 0.0330 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9444 - val_precision: 1.0000 - val_recall: 0.9167\nEpoch 18/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0355 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9444 - val_precision: 1.0000 - val_recall: 0.9167\nEpoch 19/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0381 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9444 - val_precision: 1.0000 - val_recall: 0.9167\nEpoch 20/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0294 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0713 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 21/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0239 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0434 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 22/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0223 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0329 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 23/30\n3/3 [==============================] - 67s 20s/step - loss: 0.0221 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 24/30\n3/3 [==============================] - 66s 20s/step - loss: 0.0199 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 25/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0191 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 26/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0150 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 27/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0132 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 28/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0131 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 29/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0111 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 30/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0124 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n1/1 [==============================] - 5s 5s/step - loss: 0.0243 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n\nEvaluation Results: Validation Loss - 0.02428334765136242, Validation Accuracy - 1.0, Validation Precision - 1.0, Validation Recall - 1.0\n\nFold number: 3\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n3/3 [==============================] - 119s 24s/step - loss: 0.6333 - accuracy: 0.6761 - precision: 0.6538 - recall: 0.8718 - val_loss: 0.6016 - val_accuracy: 0.7222 - val_precision: 0.6429 - val_recall: 1.0000\nEpoch 2/30\n3/3 [==============================] - 67s 20s/step - loss: 0.3893 - accuracy: 0.8592 - precision: 0.8222 - recall: 0.9487 - val_loss: 0.4677 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 3/30\n3/3 [==============================] - 66s 19s/step - loss: 0.3552 - accuracy: 0.8873 - precision: 0.8605 - recall: 0.9487 - val_loss: 0.5299 - val_accuracy: 0.7778 - val_precision: 0.6923 - val_recall: 1.0000\nEpoch 4/30\n3/3 [==============================] - 66s 19s/step - loss: 0.3040 - accuracy: 0.9155 - precision: 0.8837 - recall: 0.9744 - val_loss: 0.4682 - val_accuracy: 0.7222 - val_precision: 0.6667 - val_recall: 0.8889\nEpoch 5/30\n3/3 [==============================] - 67s 20s/step - loss: 0.2360 - accuracy: 0.9296 - precision: 0.9048 - recall: 0.9744 - val_loss: 0.4163 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 6/30\n3/3 [==============================] - 66s 19s/step - loss: 0.2285 - accuracy: 0.9437 - precision: 0.9268 - recall: 0.9744 - val_loss: 0.4183 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 7/30\n3/3 [==============================] - 66s 19s/step - loss: 0.1884 - accuracy: 0.9437 - precision: 0.9268 - recall: 0.9744 - val_loss: 0.4002 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 8/30\n3/3 [==============================] - 66s 19s/step - loss: 0.1231 - accuracy: 0.9718 - precision: 0.9512 - recall: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\nEpoch 9/30\n3/3 [==============================] - 66s 19s/step - loss: 0.1390 - accuracy: 0.9577 - precision: 0.9500 - recall: 0.9744 - val_loss: 0.3994 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 10/30\n3/3 [==============================] - 67s 20s/step - loss: 0.1020 - accuracy: 0.9859 - precision: 0.9750 - recall: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8333 - val_precision: 0.7500 - val_recall: 1.0000\nEpoch 11/30\n3/3 [==============================] - 67s 19s/step - loss: 0.0917 - accuracy: 0.9859 - precision: 0.9750 - recall: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 12/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0657 - accuracy: 0.9859 - precision: 0.9750 - recall: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\nEpoch 13/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0617 - accuracy: 0.9859 - precision: 0.9750 - recall: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\nEpoch 14/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0509 - accuracy: 0.9859 - precision: 0.9750 - recall: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 15/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0538 - accuracy: 0.9859 - precision: 0.9750 - recall: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 16/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0349 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.8333 - val_precision: 0.8000 - val_recall: 0.8889\nEpoch 17/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0255 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\nEpoch 18/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0194 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\n1/1 [==============================] - 5s 5s/step - loss: 0.3796 - accuracy: 0.7778 - precision: 0.7778 - recall: 0.7778\n\nEvaluation Results: Validation Loss - 0.37957051396369934, Validation Accuracy - 0.7777777910232544, Validation Precision - 0.7777777910232544, Validation Recall - 0.7777777910232544\n\nFold number: 4\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n3/3 [==============================] - 122s 24s/step - loss: 0.6516 - accuracy: 0.5775 - precision: 0.5758 - recall: 0.9500 - val_loss: 0.6178 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.7500\nEpoch 2/30\n3/3 [==============================] - 67s 19s/step - loss: 0.4609 - accuracy: 0.8592 - precision: 0.8409 - recall: 0.9250 - val_loss: 0.6042 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 1.0000\nEpoch 3/30\n3/3 [==============================] - 66s 20s/step - loss: 0.4642 - accuracy: 0.8028 - precision: 0.7500 - recall: 0.9750 - val_loss: 0.4950 - val_accuracy: 0.7778 - val_precision: 0.6667 - val_recall: 1.0000\nEpoch 4/30\n3/3 [==============================] - 67s 20s/step - loss: 0.4085 - accuracy: 0.8310 - precision: 0.8333 - recall: 0.8750 - val_loss: 0.4885 - val_accuracy: 0.7778 - val_precision: 0.6667 - val_recall: 1.0000\nEpoch 5/30\n3/3 [==============================] - 65s 19s/step - loss: 0.3213 - accuracy: 0.8873 - precision: 0.8636 - recall: 0.9500 - val_loss: 0.4682 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 6/30\n3/3 [==============================] - 65s 19s/step - loss: 0.3048 - accuracy: 0.9014 - precision: 0.9024 - recall: 0.9250 - val_loss: 0.5853 - val_accuracy: 0.7222 - val_precision: 0.6154 - val_recall: 1.0000\nEpoch 7/30\n3/3 [==============================] - 66s 20s/step - loss: 0.2511 - accuracy: 0.8873 - precision: 0.8636 - recall: 0.9500 - val_loss: 0.4430 - val_accuracy: 0.7778 - val_precision: 0.7000 - val_recall: 0.8750\nEpoch 8/30\n3/3 [==============================] - 66s 19s/step - loss: 0.2041 - accuracy: 0.9296 - precision: 0.9487 - recall: 0.9250 - val_loss: 0.5163 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 9/30\n3/3 [==============================] - 66s 19s/step - loss: 0.1658 - accuracy: 0.9437 - precision: 0.9286 - recall: 0.9750 - val_loss: 0.5487 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 10/30\n3/3 [==============================] - 66s 20s/step - loss: 0.1150 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.7778 - val_precision: 0.7500 - val_recall: 0.7500\nEpoch 11/30\n3/3 [==============================] - 65s 19s/step - loss: 0.1069 - accuracy: 0.9718 - precision: 0.9750 - recall: 0.9750 - val_loss: 0.4312 - val_accuracy: 0.7778 - val_precision: 0.7000 - val_recall: 0.8750\nEpoch 12/30\n3/3 [==============================] - 67s 20s/step - loss: 0.0836 - accuracy: 0.9718 - precision: 0.9750 - recall: 0.9750 - val_loss: 0.5205 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 13/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0662 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 14/30\n3/3 [==============================] - 66s 20s/step - loss: 0.0743 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 15/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0581 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.8333 - val_precision: 0.7778 - val_recall: 0.8750\nEpoch 16/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0568 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.8333 - val_precision: 0.8571 - val_recall: 0.7500\nEpoch 17/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0566 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.8889 - val_precision: 0.8000 - val_recall: 1.0000\nEpoch 18/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0386 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 19/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0411 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5957 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 20/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0348 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 21/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0383 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 22/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0367 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.8889 - val_precision: 0.8000 - val_recall: 1.0000\nEpoch 23/30\n3/3 [==============================] - 66s 20s/step - loss: 0.0350 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.7778 - val_precision: 0.7500 - val_recall: 0.7500\nEpoch 24/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0379 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.8889 - val_precision: 0.8000 - val_recall: 1.0000\nEpoch 25/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0261 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8889 - val_precision: 0.8000 - val_recall: 1.0000\nEpoch 26/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0255 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 27/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0203 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 28/30\n3/3 [==============================] - 65s 19s/step - loss: 0.0213 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 29/30\n3/3 [==============================] - 66s 20s/step - loss: 0.0248 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\nEpoch 30/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0230 - accuracy: 0.9859 - precision: 0.9756 - recall: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8333 - val_precision: 0.7273 - val_recall: 1.0000\n1/1 [==============================] - 5s 5s/step - loss: 0.4010 - accuracy: 0.8889 - precision: 0.8000 - recall: 1.0000\n\nEvaluation Results: Validation Loss - 0.40100640058517456, Validation Accuracy - 0.8888888955116272, Validation Precision - 0.800000011920929, Validation Recall - 1.0\n\nFold number: 5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n3/3 [==============================] - 118s 24s/step - loss: 0.7363 - accuracy: 0.5556 - precision: 0.5517 - recall: 0.8421 - val_loss: 0.6479 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.3000\nEpoch 2/30\n3/3 [==============================] - 68s 20s/step - loss: 0.6211 - accuracy: 0.6944 - precision: 0.8636 - recall: 0.5000 - val_loss: 0.6394 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.3000\nEpoch 3/30\n3/3 [==============================] - 67s 20s/step - loss: 0.5208 - accuracy: 0.7639 - precision: 0.9200 - recall: 0.6053 - val_loss: 0.4496 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 4/30\n3/3 [==============================] - 66s 20s/step - loss: 0.4399 - accuracy: 0.7917 - precision: 0.7255 - recall: 0.9737 - val_loss: 0.4152 - val_accuracy: 0.8824 - val_precision: 0.9000 - val_recall: 0.9000\nEpoch 5/30\n3/3 [==============================] - 64s 19s/step - loss: 0.4365 - accuracy: 0.8056 - precision: 0.7308 - recall: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 6/30\n3/3 [==============================] - 67s 20s/step - loss: 0.3676 - accuracy: 0.8889 - precision: 0.9167 - recall: 0.8684 - val_loss: 0.5835 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.6000\nEpoch 7/30\n3/3 [==============================] - 66s 19s/step - loss: 0.3514 - accuracy: 0.8889 - precision: 0.9412 - recall: 0.8421 - val_loss: 0.4844 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.7000\nEpoch 8/30\n3/3 [==============================] - 67s 20s/step - loss: 0.2919 - accuracy: 0.9306 - precision: 0.9231 - recall: 0.9474 - val_loss: 0.4374 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 9/30\n3/3 [==============================] - 67s 20s/step - loss: 0.2349 - accuracy: 0.9306 - precision: 0.9231 - recall: 0.9474 - val_loss: 0.4059 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 10/30\n3/3 [==============================] - 67s 20s/step - loss: 0.2161 - accuracy: 0.9306 - precision: 0.8837 - recall: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 11/30\n3/3 [==============================] - 67s 20s/step - loss: 0.1797 - accuracy: 0.9861 - precision: 0.9744 - recall: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 12/30\n3/3 [==============================] - 66s 20s/step - loss: 0.1437 - accuracy: 0.9722 - precision: 0.9737 - recall: 0.9737 - val_loss: 0.4644 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 13/30\n3/3 [==============================] - 67s 20s/step - loss: 0.1390 - accuracy: 0.9722 - precision: 0.9500 - recall: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 14/30\n3/3 [==============================] - 67s 20s/step - loss: 0.1126 - accuracy: 0.9861 - precision: 0.9744 - recall: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 15/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0895 - accuracy: 0.9722 - precision: 0.9500 - recall: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 16/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0848 - accuracy: 0.9722 - precision: 0.9500 - recall: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 17/30\n3/3 [==============================] - 66s 20s/step - loss: 0.0598 - accuracy: 0.9861 - precision: 0.9744 - recall: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 18/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0700 - accuracy: 0.9861 - precision: 0.9744 - recall: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 19/30\n3/3 [==============================] - 66s 20s/step - loss: 0.0433 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 20/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0441 - accuracy: 0.9861 - precision: 0.9744 - recall: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 21/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0338 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 22/30\n3/3 [==============================] - 68s 20s/step - loss: 0.0264 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.8000\nEpoch 23/30\n3/3 [==============================] - 66s 20s/step - loss: 0.0283 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\nEpoch 24/30\n3/3 [==============================] - 66s 19s/step - loss: 0.0269 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.8000\n1/1 [==============================] - 5s 5s/step - loss: 0.3660 - accuracy: 0.8235 - precision: 0.8889 - recall: 0.8000\n\nEvaluation Results: Validation Loss - 0.3659937083721161, Validation Accuracy - 0.8235294222831726, Validation Precision - 0.8888888955116272, Validation Recall - 0.800000011920929\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run kfold cross-validation on the training data only\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tpu_strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, cv \u001b[38;5;129;01min\u001b[39;00m kfold\u001b[38;5;241m.\u001b[39msplit(X, y):\n\u001b[1;32m      6\u001b[0m         X_train \u001b[38;5;241m=\u001b[39m X[train]\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:819\u001b[0m, in \u001b[0;36m_CurrentDistributionContext.__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m    814\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    815\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable scope nesting error: move call to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.distribute.set_strategy() out of `with` scope.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    818\u001b[0m         e)\n\u001b[0;32m--> 819\u001b[0m \u001b[43m_pop_per_thread_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:371\u001b[0m, in \u001b[0;36m_pop_per_thread_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pop_per_thread_mode\u001b[39m():\n\u001b[0;32m--> 371\u001b[0m   \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: pop from empty list"],"ename":"IndexError","evalue":"pop from empty list","output_type":"error"}]},{"cell_type":"code","source":"# print kfold results\nfold_loss=np.array(fold_loss)\nfold_accuracy=np.array(fold_accuracy)\nfold_precision=np.array(fold_precision)\nfold_recall=np.array(fold_recall)\n\nprint(f'Average Loss: {np.mean(fold_loss)}')\nprint(f'Average Accuracy: {np.mean(fold_accuracy)} (+/- {np.std(fold_accuracy)})')\nprint(f'Average Precision: {np.mean(fold_precision)} (+/- {np.std(fold_precision)})')\nprint(f'Average Recall: {np.mean(fold_recall)} (+/- {np.std(fold_recall)})')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:57:16.866612Z","iopub.execute_input":"2024-09-24T02:57:16.867568Z","iopub.status.idle":"2024-09-24T02:57:16.874141Z","shell.execute_reply.started":"2024-09-24T02:57:16.867523Z","shell.execute_reply":"2024-09-24T02:57:16.873011Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Average Loss: 0.2781157370656729\nAverage Accuracy: 0.8758170008659363 (+/- 0.07497845513720999)\nAverage Precision: 0.8711111187934876 (+/- 0.07875575151321046)\nAverage Recall: 0.8933333396911621 (+/- 0.09469899770066628)\n","output_type":"stream"}]},{"cell_type":"code","source":"# load the test examples and labels\ntext_files_test={}\nload_files('/kaggle/input/patient-text-test-files/patient_txt_test_files', text_files_test)\ntext_files_test = collections.OrderedDict(sorted(text_files_test.items()))\n\nX_test=[]\nfor key in text_files_test:\n    X_test.append(text_files_test[key])\nX_test=np.array(X_test)\n\ny_test=pd.read_csv('/kaggle/input/solution/Solution.csv')\ny_test.sort_values(y_test.columns[0], axis=0, inplace=True)\ny_test=y_test['Label']\ny_test.loc[y_test > 0] = 1\ny_test=np.asarray(y_test).astype('float32')\n\nX_train=X\ny_train=y","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:57:18.346638Z","iopub.execute_input":"2024-09-24T02:57:18.347063Z","iopub.status.idle":"2024-09-24T02:57:18.477786Z","shell.execute_reply.started":"2024-09-24T02:57:18.347029Z","shell.execute_reply":"2024-09-24T02:57:18.476769Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# train and evaluate the model on the full training and testing dataset\nwith tpu_strategy.scope():\n    create_run_model(X_train, X_test, y_train, y_test, fold_loss, fold_accuracy, fold_precision, fold_recall, 1)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:57:20.877454Z","iopub.execute_input":"2024-09-24T02:57:20.877882Z","iopub.status.idle":"2024-09-24T02:59:13.774161Z","shell.execute_reply.started":"2024-09-24T02:57:20.877848Z","shell.execute_reply":"2024-09-24T02:59:13.772578Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2024-09-24 02:58:28.564190: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"3/3 [==============================] - 67s 6s/step - loss: 0.7243 - accuracy: 0.4944 - precision: 0.5231 - recall: 0.7083 - val_loss: 0.5618 - val_accuracy: 0.8333 - val_precision: 0.7647 - val_recall: 1.0000\nEpoch 2/30\n3/3 [==============================] - 1s 673ms/step - loss: 0.5338 - accuracy: 0.7640 - precision: 0.7015 - recall: 0.9792 - val_loss: 0.4720 - val_accuracy: 0.9167 - val_precision: 0.8667 - val_recall: 1.0000\nEpoch 3/30\n3/3 [==============================] - 1s 678ms/step - loss: 0.4994 - accuracy: 0.7865 - precision: 0.7377 - recall: 0.9375 - val_loss: 0.4007 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 4/30\n3/3 [==============================] - 1s 647ms/step - loss: 0.3632 - accuracy: 0.8652 - precision: 0.8333 - recall: 0.9375 - val_loss: 0.3594 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 5/30\n3/3 [==============================] - 1s 655ms/step - loss: 0.3467 - accuracy: 0.8876 - precision: 0.8519 - recall: 0.9583 - val_loss: 0.3330 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 6/30\n3/3 [==============================] - 1s 435ms/step - loss: 0.2412 - accuracy: 0.9213 - precision: 0.9362 - recall: 0.9167 - val_loss: 0.3538 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 7/30\n3/3 [==============================] - 1s 424ms/step - loss: 0.1878 - accuracy: 0.9663 - precision: 0.9412 - recall: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 8/30\n3/3 [==============================] - 1s 627ms/step - loss: 0.1556 - accuracy: 0.9663 - precision: 0.9787 - recall: 0.9583 - val_loss: 0.3274 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 9/30\n3/3 [==============================] - 1s 426ms/step - loss: 0.0987 - accuracy: 0.9888 - precision: 0.9796 - recall: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9167 - val_precision: 0.8667 - val_recall: 1.0000\nEpoch 10/30\n3/3 [==============================] - 1s 655ms/step - loss: 0.0808 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9167 - val_precision: 0.8667 - val_recall: 1.0000\nEpoch 11/30\n3/3 [==============================] - 1s 622ms/step - loss: 0.0768 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9167 - val_precision: 0.9231 - val_recall: 0.9231\nEpoch 12/30\n3/3 [==============================] - 1s 441ms/step - loss: 0.0519 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9167 - val_precision: 0.8667 - val_recall: 1.0000\nEpoch 13/30\n3/3 [==============================] - 1s 442ms/step - loss: 0.0445 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.9167 - val_precision: 0.8667 - val_recall: 1.0000\nEpoch 14/30\n3/3 [==============================] - 1s 425ms/step - loss: 0.0351 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 15/30\n3/3 [==============================] - 1s 453ms/step - loss: 0.0276 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 16/30\n3/3 [==============================] - 1s 429ms/step - loss: 0.0231 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 17/30\n3/3 [==============================] - 1s 417ms/step - loss: 0.0208 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9167 - val_precision: 0.9231 - val_recall: 0.9231\nEpoch 18/30\n3/3 [==============================] - 1s 424ms/step - loss: 0.0163 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 19/30\n3/3 [==============================] - 1s 421ms/step - loss: 0.0161 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.8750 - val_precision: 0.8571 - val_recall: 0.9231\nEpoch 20/30\n3/3 [==============================] - 1s 436ms/step - loss: 0.0136 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9167 - val_precision: 0.8667 - val_recall: 1.0000\nEpoch 21/30\n3/3 [==============================] - 1s 477ms/step - loss: 0.0124 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9167 - val_precision: 0.8667 - val_recall: 1.0000\n1/1 [==============================] - 1s 581ms/step - loss: 0.2613 - accuracy: 0.9167 - precision: 0.9231 - recall: 0.9231\n\nEvaluation Results: Validation Loss - 0.2612517178058624, Validation Accuracy - 0.9166666865348816, Validation Precision - 0.9230769276618958, Validation Recall - 0.9230769276618958\n\n","output_type":"stream"}]}]}